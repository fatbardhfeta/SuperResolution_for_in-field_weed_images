# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/00_dataset.ipynb.

# %% auto 0
__all__ = ['UAVDataset', 'UAVDatasetFlightAlt', 'get_loader_flight_alt', 'get_loader']

# %% ../nbs/00_dataset.ipynb 2
from typing import Union
import numpy as np
from skimage import io as skio
from torch.utils.data import Dataset, DataLoader
import math
from patchify import patchify
from pathlib import Path
import albumentations as a
from albumentations.pytorch import ToTensorV2
import torch
from skimage.transform import resize
import cv2

# %% ../nbs/00_dataset.ipynb 3
class UAVDataset(Dataset):
    def __init__(self, img_ls, slc_size=256, b_crop=False, remove_thresh=None, transform=None):
        self.transform = transform
        self.remove_thresh = remove_thresh
        self.b_crop = b_crop  # crops image and mask to multiples of slc_size. That way we don't need to pad
        self.img_ls = img_ls
        self.img_shape = None
        self.slc_size = slc_size
        self.images = self.load_rgb(b_masks=False)
        self.masks = self.load_rgb(b_masks=True)
        self._encode_masks(self.masks)
        if self.remove_thresh:
            self.filter_masks_by_percent_background()

    def __len__(self):
        return len(self.masks)

    def _crop(self, rgb_arr):
        height = (self.img_shape[0] // self.slc_size) * self.slc_size
        width = (self.img_shape[1] // self.slc_size) * self.slc_size
        rgb_arr = rgb_arr[:height, :width, :]
        self.img_shape = rgb_arr.shape
        return rgb_arr

    def _encode_masks(self, rgb_mask):
        """
        encodes 4D numpy array
        """
        labels = np.array([[199, 199, 199], [31, 119, 180], [255, 127, 14]], dtype=np.uint8)
        rgb_mask = rgb_mask.reshape((-1, self.slc_size, 3))
        label_map = np.zeros(rgb_mask.shape[:2], dtype=np.uint8)
        for idx, label in enumerate(labels):
            label_map[(rgb_mask == np.array(label)).all(axis=2)] = idx
        self.masks = label_map.reshape((-1, self.slc_size, self.slc_size))
        return

    def filter_masks_by_percent_background(self):
        """
        removes images and masks that do have a higher value of background pixels than a certain threshold
        :param thresh: threshold [0,1[ as float, until we exclude patches
        """
        num_pixels = self.slc_size ** 2
        idc = []
        for idx, msk in enumerate(self.masks):
            uniq = np.unique(msk, return_counts=True)
            bg_idx = np.where(uniq[0] == 0)[0]  # index where the background is
            num_bg = uniq[1][bg_idx][0]
            percent_bg = num_bg / num_pixels
            if percent_bg >= self.remove_thresh:
                idc.append(idx)
        self.images = np.delete(self.images, idc, axis=0)
        self.masks = np.delete(self.masks, idc, axis=0)

    def load_rgb(self, b_masks):
        imgs = []
        img_ls = []
        if b_masks:
            img_ls = [img.replace("images","masks") for img in self.img_ls]
        else:
            img_ls = self.img_ls
        for img_str in list(sorted(img_ls)):
            img = skio.imread(img_str)
            self.img_shape = img.shape
            if self.b_crop:
                img = self._crop(img)
            patches = self.image_to_patches(image=img, b_msk=False)
            imgs.append(patches)

        imgs = np.stack(imgs)
        imgs = np.moveaxis(imgs, [0, 1, 2, 3, 4, 5, 6], [3, 4, 5, 6, 0, 1, 2])
        imgs = imgs.reshape((self.slc_size, self.slc_size, 3, -1))
        imgs = np.moveaxis(imgs, -1, 0)
        return imgs

    def image_to_patches(self, image, b_msk=False):
        x = int(math.ceil(image.shape[0] / (self.slc_size * 1.0)))
        y = int(math.ceil(image.shape[1] / (self.slc_size * 1.0)))
        padded_shape = (x * self.slc_size, y * self.slc_size)
        if not b_msk:
            padded_rgb_image = np.zeros((padded_shape[0], padded_shape[1], 3), dtype=np.uint8)
            padded_rgb_image[:image.shape[0], :image.shape[1]] = image
            patches = patchify(padded_rgb_image, (self.slc_size, self.slc_size, 3), step=self.slc_size)
        else:
            padded_rgb_image = np.zeros((padded_shape[0], padded_shape[1]), dtype=np.uint8)
            padded_rgb_image[:image.shape[0], :image.shape[1]] = image
            patches = patchify(padded_rgb_image, (self.slc_size, self.slc_size), step=self.slc_size)
        return patches

    def __getitem__(self, idx):
        image = self.images[idx]
        mask = self.masks[idx]
        if self.transform is not None:
            augmentations = self.transform(image=image, mask=mask)
            image = augmentations["image"]
            mask = augmentations["mask"]
        return image, mask


class UAVDatasetPatches(Dataset):
    def __init__(self, img_list, msk_list, transform=None):
        '''
        img_ls: list of image Paths to load
        msk_ls: list of mask Paths to load
        loads the dataset from a list of images and masks
        '''
        self.transform = transform
        self.img_list= img_list
        self.msk_list= msk_list
        assert len(self.img_list) == len(self.msk_list), "Image and Mask Patches have different lengths."
    def __len__(self):
        return len(self.img_list)

    def __getitem__(self, idx):
        image = cv2.imread(str(self.img_list[idx]))
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        mask = cv2.imread(str(self.msk_list[idx]), cv2.IMREAD_GRAYSCALE) # load as np.float32
        if self.transform is not None:
            augmentations = self.transform(image=image, mask=mask)
            image = augmentations["image"]
            mask = augmentations["mask"]
        return image, mask


# %% ../nbs/00_dataset.ipynb 5
def get_loader(
        img_ls: list,  # Path to the data folder. Must have "images" and "masks" as subfolder
        slc_size: int,  # size of the patches
        b_crop: bool,  # remove patches that would not be of slc_size
        filter_thresh: Union[None, float],  # percentage of background pixels for removing a patch
        split: str,  # "train", "val" or "test"
        generator: torch.Generator,  # Generator to be used for reproducibility
        batch_size: int = 20,  # size of a batch for training and testing
        num_workers: int = 2,  # number of workers
        pin_memory: bool = False,  # whether to pin memory or not
):
    """
    Loads the dataset as a PyTorch dataloader object for batching
    """
    print(f"Loading split {split}...")
    if split == "train":
        transforms = a.Compose(
            [a.HorizontalFlip(),
             a.VerticalFlip(),
             a.RandomRotate90(),
             a.Transpose(),
             #a.CLAHE(always_apply=True, p=1.0),
             a.Normalize(mean=(0.73799304, 0.5964489, 0.37777742), std=(0.16867594, 0.15078324, 0.13606868)),
             ToTensorV2()])
        shuffle = True

    elif any(substring in split for substring in ['val', 'test']):
        transforms = a.Compose([
            #a.CLAHE(always_apply=True, p=1.0),
            a.Normalize(mean=(0.73799304, 0.5964489, 0.37777742), std=(0.16867594, 0.15078324, 0.13606868)),
            ToTensorV2()])
        shuffle = False
    else:
        raise ValueError(f"Wrong name of labels_csv, please use one of ['train', 'val', 'test', 'final_test']")
    ds = UAVDataset(img_ls=img_ls, slc_size=slc_size, b_crop=b_crop, remove_thresh=filter_thresh, transform=transforms)
    dataloader = DataLoader(ds, batch_size=batch_size, shuffle=shuffle, pin_memory=pin_memory, num_workers=num_workers,
                            generator=generator)
    print(f"Final shape: {ds.images.shape}")
    return dataloader
